{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "from finta import TA as ta\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Setting these options will allow for reviewing more of the DataFrames\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 2000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04-06 15:00:00+00:00</th>\n",
       "      <td>44308.281250</td>\n",
       "      <td>44308.281250</td>\n",
       "      <td>43845.363281</td>\n",
       "      <td>44151.644531</td>\n",
       "      <td>44151.644531</td>\n",
       "      <td>1156792320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06 16:00:00+00:00</th>\n",
       "      <td>44155.347656</td>\n",
       "      <td>44231.949219</td>\n",
       "      <td>43729.031250</td>\n",
       "      <td>43764.480469</td>\n",
       "      <td>43764.480469</td>\n",
       "      <td>1157632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06 17:00:00+00:00</th>\n",
       "      <td>43809.972656</td>\n",
       "      <td>43941.277344</td>\n",
       "      <td>43538.171875</td>\n",
       "      <td>43906.554688</td>\n",
       "      <td>43906.554688</td>\n",
       "      <td>944455680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06 18:00:00+00:00</th>\n",
       "      <td>43905.808594</td>\n",
       "      <td>44207.109375</td>\n",
       "      <td>43452.957031</td>\n",
       "      <td>43643.773438</td>\n",
       "      <td>43643.773438</td>\n",
       "      <td>1831428096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06 18:37:00+00:00</th>\n",
       "      <td>43676.156250</td>\n",
       "      <td>43676.156250</td>\n",
       "      <td>43676.156250</td>\n",
       "      <td>43676.156250</td>\n",
       "      <td>43676.156250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Open          High           Low         Close     Adj Close      Volume\n",
       "2022-04-06 15:00:00+00:00  44308.281250  44308.281250  43845.363281  44151.644531  44151.644531  1156792320\n",
       "2022-04-06 16:00:00+00:00  44155.347656  44231.949219  43729.031250  43764.480469  43764.480469  1157632000\n",
       "2022-04-06 17:00:00+00:00  43809.972656  43941.277344  43538.171875  43906.554688  43906.554688   944455680\n",
       "2022-04-06 18:00:00+00:00  43905.808594  44207.109375  43452.957031  43643.773438  43643.773438  1831428096\n",
       "2022-04-06 18:37:00+00:00  43676.156250  43676.156250  43676.156250  43676.156250  43676.156250           0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = yf.download(\"BTC-USD\", interval=\"1h\", start=\"2020-05-01\", end=pd.to_datetime('today'))\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendData(maindf, dataarray, namesarray=None):\n",
    "    if namesarray==None:\n",
    "        return maindf.join(pd.DataFrame(dataarray), how='outer')\n",
    "    return maindf.join(pd.DataFrame(dataarray,columns=namesarray), how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Oscillators ###\n",
    "## RSI\n",
    "df = appendData(df,ta.RSI(df))\n",
    "## Sto-%K\n",
    "df = appendData(df,ta.STOCH(df))\n",
    "## CCI\n",
    "df = appendData(df,ta.CCI(df))\n",
    "## ADX\n",
    "df = appendData(df,ta.ADX(df))\n",
    "## DMI (Added to aid in interpreting ADX)\n",
    "df = appendData(df,ta.DMI(df, 14))\n",
    "## Awesome\n",
    "df = appendData(df,ta.AO(df))\n",
    "## Momentum\n",
    "df = appendData(df,ta.MOM(df,10))\n",
    "## MACD (We rename the undescriptive \"SIGNAL\" here)\n",
    "df = appendData(df,ta.MACD(df)).rename(columns={\"SIGNAL\": \"MACD SIGNAL\"})\n",
    "## Sto-RSI\n",
    "df = appendData(df,ta.STOCHRSI(df))\n",
    "## Williams %R\n",
    "df = appendData(df,ta.WILLIAMS(df))\n",
    "## Bull-Bear Power\n",
    "df = appendData(df,ta.EBBP(df))\n",
    "## Ultimate (FinTA does not name this column, so we must)\n",
    "df = appendData(df,ta.UO(df),[\"UO\"])\n",
    "### Moving Averages ###\n",
    "sma_ema_averages = [5, 10, 20, 30, 50, 100, 200]\n",
    "## SMA, EMA\n",
    "for i in sma_ema_averages:\n",
    "  df = appendData(df,ta.SMA(df, i))\n",
    "  df = appendData(df,ta.EMA(df, i))\n",
    "## VWMA\n",
    "df = appendData(df, ta.VAMA(df, 20))\n",
    "## Hull\n",
    "df = appendData(df,ta.HMA(df, 9))\n",
    "# Ichimoku -- Base (Kijun) and Conversion (Tenkan) Only\n",
    "df = appendData(df,ta.ICHIMOKU(df).drop(['senkou_span_a','SENKOU','CHIKOU'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8278\n",
      "         1.0       1.00      0.05      0.09       185\n",
      "\n",
      "    accuracy                           0.98      8463\n",
      "   macro avg       0.99      0.52      0.54      8463\n",
      "weighted avg       0.98      0.98      0.97      8463\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      7387\n",
      "         1.0       0.92      0.06      0.12       177\n",
      "\n",
      "    accuracy                           0.98      7564\n",
      "   macro avg       0.95      0.53      0.55      7564\n",
      "weighted avg       0.98      0.98      0.97      7564\n",
      "\n",
      "4_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.99      8196\n",
      "         1.0       0.91      0.20      0.33       267\n",
      "\n",
      "    accuracy                           0.97      8463\n",
      "   macro avg       0.94      0.60      0.66      8463\n",
      "weighted avg       0.97      0.97      0.97      8463\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.99      7296\n",
      "         1.0       0.83      0.23      0.37       264\n",
      "\n",
      "    accuracy                           0.97      7560\n",
      "   macro avg       0.90      0.62      0.68      7560\n",
      "weighted avg       0.97      0.97      0.96      7560\n",
      "\n",
      "5_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.99      8116\n",
      "         1.0       0.88      0.34      0.49       347\n",
      "\n",
      "    accuracy                           0.97      8463\n",
      "   macro avg       0.92      0.67      0.74      8463\n",
      "weighted avg       0.97      0.97      0.96      8463\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      7240\n",
      "         1.0       0.79      0.36      0.49       315\n",
      "\n",
      "    accuracy                           0.97      7555\n",
      "   macro avg       0.88      0.68      0.74      7555\n",
      "weighted avg       0.96      0.97      0.96      7555\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>14 period RSI</th>\n",
       "      <th>14 period STOCH %K</th>\n",
       "      <th>20 period CCI</th>\n",
       "      <th>14 period ADX.</th>\n",
       "      <th>DI+</th>\n",
       "      <th>DI-</th>\n",
       "      <th>AO</th>\n",
       "      <th>MOM</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD SIGNAL</th>\n",
       "      <th>14 period stochastic RSI.</th>\n",
       "      <th>14 Williams %R</th>\n",
       "      <th>Bull.</th>\n",
       "      <th>Bear.</th>\n",
       "      <th>UO</th>\n",
       "      <th>5 period SMA</th>\n",
       "      <th>5 period EMA</th>\n",
       "      <th>10 period SMA</th>\n",
       "      <th>10 period EMA</th>\n",
       "      <th>20 period SMA</th>\n",
       "      <th>20 period EMA</th>\n",
       "      <th>30 period SMA</th>\n",
       "      <th>30 period EMA</th>\n",
       "      <th>50 period SMA</th>\n",
       "      <th>50 period EMA</th>\n",
       "      <th>100 period SMA</th>\n",
       "      <th>100 period EMA</th>\n",
       "      <th>200 period SMA</th>\n",
       "      <th>200 period EMA</th>\n",
       "      <th>20 period VAMA</th>\n",
       "      <th>9 period HMA.</th>\n",
       "      <th>TENKAN</th>\n",
       "      <th>KIJUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-10 06:00:00+00:00</th>\n",
       "      <td>8644.215820</td>\n",
       "      <td>8644.721680</td>\n",
       "      <td>8607.754883</td>\n",
       "      <td>8623.298828</td>\n",
       "      <td>8623.298828</td>\n",
       "      <td>479838208</td>\n",
       "      <td>16.961004</td>\n",
       "      <td>8.422995</td>\n",
       "      <td>-105.862044</td>\n",
       "      <td>49.377536</td>\n",
       "      <td>9.448129</td>\n",
       "      <td>64.758805</td>\n",
       "      <td>-921.139223</td>\n",
       "      <td>-1096.724609</td>\n",
       "      <td>-311.527829</td>\n",
       "      <td>-214.518810</td>\n",
       "      <td>0.300804</td>\n",
       "      <td>-91.577005</td>\n",
       "      <td>-359.981754</td>\n",
       "      <td>-396.948551</td>\n",
       "      <td>26.567172</td>\n",
       "      <td>8632.405859</td>\n",
       "      <td>8694.213246</td>\n",
       "      <td>8954.757715</td>\n",
       "      <td>8900.308810</td>\n",
       "      <td>9328.175391</td>\n",
       "      <td>9182.601878</td>\n",
       "      <td>9483.132096</td>\n",
       "      <td>9332.785485</td>\n",
       "      <td>9656.307734</td>\n",
       "      <td>9451.915232</td>\n",
       "      <td>9499.726240</td>\n",
       "      <td>9446.526063</td>\n",
       "      <td>9200.590874</td>\n",
       "      <td>9349.498826</td>\n",
       "      <td>9197.923680</td>\n",
       "      <td>8479.523872</td>\n",
       "      <td>9088.888672</td>\n",
       "      <td>9200.460449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-10 07:00:00+00:00</th>\n",
       "      <td>8627.400391</td>\n",
       "      <td>8819.001953</td>\n",
       "      <td>8623.360352</td>\n",
       "      <td>8819.001953</td>\n",
       "      <td>8819.001953</td>\n",
       "      <td>902176768</td>\n",
       "      <td>30.332235</td>\n",
       "      <td>24.123710</td>\n",
       "      <td>-76.317886</td>\n",
       "      <td>49.765079</td>\n",
       "      <td>17.556694</td>\n",
       "      <td>60.133174</td>\n",
       "      <td>-883.479274</td>\n",
       "      <td>-826.564453</td>\n",
       "      <td>-300.662798</td>\n",
       "      <td>-231.747608</td>\n",
       "      <td>0.287068</td>\n",
       "      <td>-75.876290</td>\n",
       "      <td>-159.172697</td>\n",
       "      <td>-354.814299</td>\n",
       "      <td>51.046554</td>\n",
       "      <td>8658.628516</td>\n",
       "      <td>8735.809482</td>\n",
       "      <td>8872.101270</td>\n",
       "      <td>8885.525745</td>\n",
       "      <td>9286.332471</td>\n",
       "      <td>9147.973314</td>\n",
       "      <td>9447.455241</td>\n",
       "      <td>9299.638133</td>\n",
       "      <td>9634.803555</td>\n",
       "      <td>9427.089527</td>\n",
       "      <td>9498.071387</td>\n",
       "      <td>9433.910694</td>\n",
       "      <td>9200.358950</td>\n",
       "      <td>9343.483668</td>\n",
       "      <td>9133.692551</td>\n",
       "      <td>8601.843981</td>\n",
       "      <td>9088.888672</td>\n",
       "      <td>9179.400879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-10 08:00:00+00:00</th>\n",
       "      <td>8824.740234</td>\n",
       "      <td>8882.166992</td>\n",
       "      <td>8814.505859</td>\n",
       "      <td>8841.403320</td>\n",
       "      <td>8841.403320</td>\n",
       "      <td>1132785664</td>\n",
       "      <td>31.688194</td>\n",
       "      <td>26.072374</td>\n",
       "      <td>-56.623152</td>\n",
       "      <td>49.665297</td>\n",
       "      <td>19.431512</td>\n",
       "      <td>55.837945</td>\n",
       "      <td>-805.360668</td>\n",
       "      <td>-791.199219</td>\n",
       "      <td>-286.936949</td>\n",
       "      <td>-242.785476</td>\n",
       "      <td>0.273877</td>\n",
       "      <td>-73.927626</td>\n",
       "      <td>-76.468897</td>\n",
       "      <td>-144.130030</td>\n",
       "      <td>50.540786</td>\n",
       "      <td>8696.899609</td>\n",
       "      <td>8771.007428</td>\n",
       "      <td>8792.981348</td>\n",
       "      <td>8877.503486</td>\n",
       "      <td>9246.788770</td>\n",
       "      <td>9118.776171</td>\n",
       "      <td>9413.024935</td>\n",
       "      <td>9270.074574</td>\n",
       "      <td>9613.416582</td>\n",
       "      <td>9404.116483</td>\n",
       "      <td>9496.546104</td>\n",
       "      <td>9422.002871</td>\n",
       "      <td>9200.485542</td>\n",
       "      <td>9337.798611</td>\n",
       "      <td>9107.614854</td>\n",
       "      <td>8736.865129</td>\n",
       "      <td>9056.945312</td>\n",
       "      <td>9176.946289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-10 09:00:00+00:00</th>\n",
       "      <td>8835.525391</td>\n",
       "      <td>8856.499023</td>\n",
       "      <td>8817.598633</td>\n",
       "      <td>8824.708008</td>\n",
       "      <td>8824.708008</td>\n",
       "      <td>116449280</td>\n",
       "      <td>31.200794</td>\n",
       "      <td>25.090666</td>\n",
       "      <td>-52.599221</td>\n",
       "      <td>49.572643</td>\n",
       "      <td>18.043547</td>\n",
       "      <td>51.849519</td>\n",
       "      <td>-722.894764</td>\n",
       "      <td>-809.125977</td>\n",
       "      <td>-274.244962</td>\n",
       "      <td>-249.077373</td>\n",
       "      <td>0.263084</td>\n",
       "      <td>-74.909334</td>\n",
       "      <td>-83.004311</td>\n",
       "      <td>-121.904702</td>\n",
       "      <td>51.805118</td>\n",
       "      <td>8751.481055</td>\n",
       "      <td>8788.907621</td>\n",
       "      <td>8712.068750</td>\n",
       "      <td>8867.904308</td>\n",
       "      <td>9203.677051</td>\n",
       "      <td>9090.769680</td>\n",
       "      <td>9378.185286</td>\n",
       "      <td>9241.341226</td>\n",
       "      <td>9591.941387</td>\n",
       "      <td>9381.389870</td>\n",
       "      <td>9494.851094</td>\n",
       "      <td>9410.002376</td>\n",
       "      <td>9200.671982</td>\n",
       "      <td>9331.996850</td>\n",
       "      <td>9106.682206</td>\n",
       "      <td>8834.239771</td>\n",
       "      <td>8700.238281</td>\n",
       "      <td>9141.539551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-10 10:00:00+00:00</th>\n",
       "      <td>8795.744141</td>\n",
       "      <td>8825.411133</td>\n",
       "      <td>8773.115234</td>\n",
       "      <td>8818.807617</td>\n",
       "      <td>8818.807617</td>\n",
       "      <td>16891904</td>\n",
       "      <td>31.019206</td>\n",
       "      <td>24.607489</td>\n",
       "      <td>-51.070972</td>\n",
       "      <td>49.605871</td>\n",
       "      <td>16.754722</td>\n",
       "      <td>50.314929</td>\n",
       "      <td>-649.297076</td>\n",
       "      <td>71.595703</td>\n",
       "      <td>-261.646485</td>\n",
       "      <td>-251.591196</td>\n",
       "      <td>0.251959</td>\n",
       "      <td>-75.392511</td>\n",
       "      <td>-96.849956</td>\n",
       "      <td>-149.145855</td>\n",
       "      <td>52.742767</td>\n",
       "      <td>8785.443945</td>\n",
       "      <td>8798.874287</td>\n",
       "      <td>8719.228320</td>\n",
       "      <td>8858.977637</td>\n",
       "      <td>9158.845459</td>\n",
       "      <td>9064.868531</td>\n",
       "      <td>9342.597786</td>\n",
       "      <td>9214.080975</td>\n",
       "      <td>9572.377734</td>\n",
       "      <td>9359.323425</td>\n",
       "      <td>9493.231631</td>\n",
       "      <td>9398.127878</td>\n",
       "      <td>9200.768970</td>\n",
       "      <td>9326.201838</td>\n",
       "      <td>9035.705515</td>\n",
       "      <td>8878.213122</td>\n",
       "      <td>8700.238281</td>\n",
       "      <td>9141.539551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close    Adj Close      Volume  14 period RSI  14 period STOCH %K  20 period CCI  14 period ADX.        DI+        DI-          AO          MOM        MACD  MACD SIGNAL  14 period stochastic RSI.  14 Williams %R       Bull.       Bear.         UO  5 period SMA  5 period EMA  10 period SMA  10 period EMA  20 period SMA  20 period EMA  30 period SMA  30 period EMA  50 period SMA  50 period EMA  100 period SMA  100 period EMA  200 period SMA  200 period EMA  20 period VAMA  9 period HMA.       TENKAN        KIJUN\n",
       "2020-05-10 06:00:00+00:00  8644.215820  8644.721680  8607.754883  8623.298828  8623.298828   479838208      16.961004            8.422995    -105.862044       49.377536   9.448129  64.758805 -921.139223 -1096.724609 -311.527829  -214.518810                   0.300804      -91.577005 -359.981754 -396.948551  26.567172   8632.405859   8694.213246    8954.757715    8900.308810    9328.175391    9182.601878    9483.132096    9332.785485    9656.307734    9451.915232     9499.726240     9446.526063     9200.590874     9349.498826     9197.923680    8479.523872  9088.888672  9200.460449\n",
       "2020-05-10 07:00:00+00:00  8627.400391  8819.001953  8623.360352  8819.001953  8819.001953   902176768      30.332235           24.123710     -76.317886       49.765079  17.556694  60.133174 -883.479274  -826.564453 -300.662798  -231.747608                   0.287068      -75.876290 -159.172697 -354.814299  51.046554   8658.628516   8735.809482    8872.101270    8885.525745    9286.332471    9147.973314    9447.455241    9299.638133    9634.803555    9427.089527     9498.071387     9433.910694     9200.358950     9343.483668     9133.692551    8601.843981  9088.888672  9179.400879\n",
       "2020-05-10 08:00:00+00:00  8824.740234  8882.166992  8814.505859  8841.403320  8841.403320  1132785664      31.688194           26.072374     -56.623152       49.665297  19.431512  55.837945 -805.360668  -791.199219 -286.936949  -242.785476                   0.273877      -73.927626  -76.468897 -144.130030  50.540786   8696.899609   8771.007428    8792.981348    8877.503486    9246.788770    9118.776171    9413.024935    9270.074574    9613.416582    9404.116483     9496.546104     9422.002871     9200.485542     9337.798611     9107.614854    8736.865129  9056.945312  9176.946289\n",
       "2020-05-10 09:00:00+00:00  8835.525391  8856.499023  8817.598633  8824.708008  8824.708008   116449280      31.200794           25.090666     -52.599221       49.572643  18.043547  51.849519 -722.894764  -809.125977 -274.244962  -249.077373                   0.263084      -74.909334  -83.004311 -121.904702  51.805118   8751.481055   8788.907621    8712.068750    8867.904308    9203.677051    9090.769680    9378.185286    9241.341226    9591.941387    9381.389870     9494.851094     9410.002376     9200.671982     9331.996850     9106.682206    8834.239771  8700.238281  9141.539551\n",
       "2020-05-10 10:00:00+00:00  8795.744141  8825.411133  8773.115234  8818.807617  8818.807617    16891904      31.019206           24.607489     -51.070972       49.605871  16.754722  50.314929 -649.297076    71.595703 -261.646485  -251.591196                   0.251959      -75.392511  -96.849956 -149.145855  52.742767   8785.443945   8798.874287    8719.228320    8858.977637    9158.845459    9064.868531    9342.597786    9214.080975    9572.377734    9359.323425     9493.231631     9398.127878     9200.768970     9326.201838     9035.705515    8878.213122  8700.238281  9141.539551"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the pct_change function to generate the returns from \"close\"\n",
    "#df[\"actual_return\"] = df[\"Close\"].pct_change()\n",
    "i = 3\n",
    "i_end = 5\n",
    "model = SVC()\n",
    "percent_threshold = .03\n",
    "investment_amount = 10000\n",
    "training_length = 12\n",
    "while i <= i_end:\n",
    "    column_name = str(i) + \"_period_return\"\n",
    "    df[column_name] = df[\"Close\"].pct_change(periods=i)\n",
    "    # Initialize the new `Signal` column\n",
    "    signal_column_name = str(i) + \"_signal\"\n",
    "    df[signal_column_name] = 0.0\n",
    "    # Generate signal to buy stock long\n",
    "    df.loc[(df[column_name] >= (percent_threshold)), signal_column_name] = 1\n",
    "    # Drop all NaN values from the DataFrame\n",
    "    df = df.dropna()\n",
    "    y = df[signal_column_name]\n",
    "    # set up X for ml \n",
    "    X = df[[\"14 period RSI\", \"14 period STOCH %K\", \"20 period CCI\", \"14 period ADX.\", \"DI+\", \"DI-\", \"AO\", \"MOM\", \"MACD\", \"MACD SIGNAL\", \"14 period stochastic RSI.\", \"14 Williams %R\", \"Bull.\", \"Bear.\", \"UO\", \"5 period SMA\", \"5 period EMA\", \"10 period SMA\", \"10 period EMA\", \"20 period SMA\", \"20 period EMA\", \"30 period SMA\", \"30 period EMA\", \"50 period SMA\", \"50 period EMA\", \"100 period SMA\", \"100 period EMA\", \"200 period SMA\", \"200 period EMA\", \"20 period VAMA\", \"9 period HMA.\", \"TENKAN\", \"KIJUN\"]].shift().dropna().copy()\n",
    "    y_count = y.value_counts()\n",
    "    training_begin = X.index.min()\n",
    "    # Use the following code to select the ending period for the training data: `training_end = X.index.min() + DateOffset(months=3)`\n",
    "    training_end = X.index.min() + DateOffset(months=training_length)\n",
    "    # Generate the X_train and y_train DataFrames using loc to select the rows from `training_begin` up to `training_end`\n",
    "    # Hint: Use `loc[training_begin:training_end]` for X_train and y_train\n",
    "    X_train = X.loc[training_begin:training_end]\n",
    "    y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "    # Generate the X_test and y_test DataFrames using loc to select from `training_end` to the last row in the DataFrame.\n",
    "    # Hint: Use `loc[training_end:]` for X_test and y_test\n",
    "    X_test = X.loc[training_end:]\n",
    "    y_test = y.loc[training_end:]\n",
    "\n",
    "    # Use StandardScaler to scale the X_train and X_test data.\n",
    "    scaler = StandardScaler()\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    " \n",
    "    # Fit the model to the data using X_train_scaled and y_train\n",
    "    model = model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Use the trained model to predict the trading signals for the training data.\n",
    "    training_signal_predictions = model.predict(X_train_scaled)\n",
    "\n",
    "    # Evaluate the model using a classification report\n",
    "    training_report_train = classification_report(y_train, training_signal_predictions)\n",
    "    print(column_name)\n",
    "    print(\"Training Report\")\n",
    "    print(training_report_train)\n",
    "\n",
    "    # Use the trained model to predict the trading signals for the testing data.\n",
    "    testing_signal_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model's ability to predict the trading signal for the testing data using a classification report\n",
    "    training_report_test = classification_report(y_test, testing_signal_predictions)\n",
    "    print(\"Testing Report\")\n",
    "    print(training_report_test)\n",
    "\n",
    "    df = df.drop([column_name, signal_column_name], axis=1)\n",
    "    i+=1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-04-02 16:00:00+00:00             0\n",
       "2022-04-02 17:00:00+00:00             0\n",
       "2022-04-02 18:00:00+00:00    1172469760\n",
       "2022-04-02 19:00:00+00:00      99033088\n",
       "2022-04-02 20:00:00+00:00     325091328\n",
       "2022-04-02 21:00:00+00:00     111712256\n",
       "2022-04-02 22:00:00+00:00             0\n",
       "2022-04-02 23:00:00+00:00             0\n",
       "2022-04-03 00:00:00+00:00     109555712\n",
       "2022-04-03 01:00:00+00:00             0\n",
       "2022-04-03 02:00:00+00:00             0\n",
       "2022-04-03 03:00:00+00:00             0\n",
       "2022-04-03 04:00:00+00:00     167596032\n",
       "2022-04-03 05:00:00+00:00      13764608\n",
       "2022-04-03 06:00:00+00:00     541728768\n",
       "2022-04-03 07:00:00+00:00             0\n",
       "2022-04-03 08:00:00+00:00             0\n",
       "2022-04-03 09:00:00+00:00      91154432\n",
       "2022-04-03 10:00:00+00:00             0\n",
       "2022-04-03 11:00:00+00:00             0\n",
       "2022-04-03 12:00:00+00:00             0\n",
       "2022-04-03 13:00:00+00:00     139196416\n",
       "2022-04-03 14:00:00+00:00             0\n",
       "2022-04-03 15:00:00+00:00             0\n",
       "2022-04-03 16:00:00+00:00             0\n",
       "2022-04-03 17:00:00+00:00        765952\n",
       "2022-04-03 18:00:00+00:00             0\n",
       "2022-04-03 19:00:00+00:00     398100480\n",
       "2022-04-03 20:00:00+00:00             0\n",
       "2022-04-03 21:00:00+00:00     340869120\n",
       "2022-04-03 22:00:00+00:00    2549780480\n",
       "2022-04-03 23:00:00+00:00     758032384\n",
       "2022-04-04 00:00:00+00:00    1105248256\n",
       "2022-04-04 01:00:00+00:00             0\n",
       "2022-04-04 02:00:00+00:00     325373952\n",
       "2022-04-04 03:00:00+00:00      88788992\n",
       "2022-04-04 04:00:00+00:00     315846656\n",
       "2022-04-04 05:00:00+00:00     145416192\n",
       "2022-04-04 06:00:00+00:00             0\n",
       "2022-04-04 07:00:00+00:00     164020224\n",
       "2022-04-04 08:00:00+00:00     689442816\n",
       "2022-04-04 09:00:00+00:00     323958784\n",
       "2022-04-04 10:00:00+00:00     735748096\n",
       "2022-04-04 11:00:00+00:00     468754432\n",
       "2022-04-04 12:00:00+00:00     179089408\n",
       "2022-04-04 13:00:00+00:00     363237376\n",
       "2022-04-04 14:00:00+00:00     945186816\n",
       "2022-04-04 15:00:00+00:00     784728064\n",
       "2022-04-04 16:00:00+00:00             0\n",
       "2022-04-04 17:00:00+00:00     985747456\n",
       "2022-04-04 18:00:00+00:00     930326528\n",
       "2022-04-04 19:00:00+00:00     234338304\n",
       "2022-04-04 20:00:00+00:00    1810339840\n",
       "2022-04-04 21:00:00+00:00     658077696\n",
       "2022-04-04 22:00:00+00:00             0\n",
       "2022-04-04 23:00:00+00:00             0\n",
       "2022-04-05 00:00:00+00:00             0\n",
       "2022-04-05 01:00:00+00:00             0\n",
       "2022-04-05 02:00:00+00:00             0\n",
       "2022-04-05 03:00:00+00:00      39510016\n",
       "2022-04-05 04:00:00+00:00      20785152\n",
       "2022-04-05 05:00:00+00:00             0\n",
       "2022-04-05 06:00:00+00:00          8192\n",
       "2022-04-05 07:00:00+00:00     157693952\n",
       "2022-04-05 08:00:00+00:00             0\n",
       "2022-04-05 09:00:00+00:00             0\n",
       "2022-04-05 10:00:00+00:00             0\n",
       "2022-04-05 11:00:00+00:00             0\n",
       "2022-04-05 12:00:00+00:00    1168560128\n",
       "2022-04-05 13:00:00+00:00     905492480\n",
       "2022-04-05 14:00:00+00:00    1974464512\n",
       "2022-04-05 15:00:00+00:00             0\n",
       "2022-04-05 16:00:00+00:00             0\n",
       "2022-04-05 17:00:00+00:00      74612736\n",
       "2022-04-05 18:00:00+00:00             0\n",
       "2022-04-05 19:00:00+00:00     871667712\n",
       "2022-04-05 20:00:00+00:00             0\n",
       "2022-04-05 21:00:00+00:00             0\n",
       "2022-04-05 22:00:00+00:00             0\n",
       "2022-04-05 23:00:00+00:00     391081984\n",
       "2022-04-06 00:00:00+00:00    2746912768\n",
       "2022-04-06 01:00:00+00:00     858413056\n",
       "2022-04-06 02:00:00+00:00     270702592\n",
       "2022-04-06 03:00:00+00:00     113774592\n",
       "2022-04-06 04:00:00+00:00     284514304\n",
       "2022-04-06 05:00:00+00:00     317771776\n",
       "2022-04-06 06:00:00+00:00     413202432\n",
       "2022-04-06 07:00:00+00:00     306831360\n",
       "2022-04-06 08:00:00+00:00     329052160\n",
       "2022-04-06 09:00:00+00:00     129712128\n",
       "2022-04-06 10:00:00+00:00     441868288\n",
       "2022-04-06 11:00:00+00:00    1418063872\n",
       "2022-04-06 12:00:00+00:00             0\n",
       "2022-04-06 13:00:00+00:00      72945664\n",
       "2022-04-06 14:00:00+00:00     557228032\n",
       "2022-04-06 15:00:00+00:00    1156792320\n",
       "2022-04-06 16:00:00+00:00    1157632000\n",
       "2022-04-06 17:00:00+00:00     944455680\n",
       "2022-04-06 18:00:00+00:00     571506688\n",
       "2022-04-06 18:09:00+00:00             0\n",
       "Name: Volume, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CASE 2 - Neural network.\n",
    "\n",
    "volume_df = df[\"Volume\"]\n",
    "volume_df.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      8279\n",
      "         1.0       0.87      0.33      0.48       184\n",
      "\n",
      "    accuracy                           0.98      8463\n",
      "   macro avg       0.93      0.67      0.74      8463\n",
      "weighted avg       0.98      0.98      0.98      8463\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      7361\n",
      "         1.0       0.35      0.20      0.26       179\n",
      "\n",
      "    accuracy                           0.97      7540\n",
      "   macro avg       0.67      0.60      0.62      7540\n",
      "weighted avg       0.97      0.97      0.97      7540\n",
      "\n",
      "4_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8199\n",
      "         1.0       0.88      0.52      0.65       264\n",
      "\n",
      "    accuracy                           0.98      8463\n",
      "   macro avg       0.93      0.76      0.82      8463\n",
      "weighted avg       0.98      0.98      0.98      8463\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      7272\n",
      "         1.0       0.45      0.34      0.39       264\n",
      "\n",
      "    accuracy                           0.96      7536\n",
      "   macro avg       0.72      0.66      0.69      7536\n",
      "weighted avg       0.96      0.96      0.96      7536\n",
      "\n",
      "5_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8119\n",
      "         1.0       0.86      0.59      0.70       344\n",
      "\n",
      "    accuracy                           0.98      8463\n",
      "   macro avg       0.92      0.79      0.84      8463\n",
      "weighted avg       0.98      0.98      0.98      8463\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98      7216\n",
      "         1.0       0.53      0.40      0.46       315\n",
      "\n",
      "    accuracy                           0.96      7531\n",
      "   macro avg       0.75      0.69      0.72      7531\n",
      "weighted avg       0.96      0.96      0.96      7531\n",
      "\n",
      "6_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      8058\n",
      "         1.0       0.87      0.69      0.77       405\n",
      "\n",
      "    accuracy                           0.98      8463\n",
      "   macro avg       0.93      0.84      0.88      8463\n",
      "weighted avg       0.98      0.98      0.98      8463\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.97      7136\n",
      "         1.0       0.54      0.45      0.49       389\n",
      "\n",
      "    accuracy                           0.95      7525\n",
      "   macro avg       0.76      0.72      0.73      7525\n",
      "weighted avg       0.95      0.95      0.95      7525\n",
      "\n",
      "7_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      7972\n",
      "         1.0       0.85      0.71      0.78       492\n",
      "\n",
      "    accuracy                           0.98      8464\n",
      "   macro avg       0.92      0.85      0.88      8464\n",
      "weighted avg       0.97      0.98      0.98      8464\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      7050\n",
      "         1.0       0.56      0.50      0.53       467\n",
      "\n",
      "    accuracy                           0.94      7517\n",
      "   macro avg       0.77      0.74      0.75      7517\n",
      "weighted avg       0.94      0.94      0.94      7517\n",
      "\n",
      "8_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      7911\n",
      "         1.0       0.87      0.76      0.81       553\n",
      "\n",
      "    accuracy                           0.98      8464\n",
      "   macro avg       0.93      0.88      0.90      8464\n",
      "weighted avg       0.98      0.98      0.98      8464\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97      6987\n",
      "         1.0       0.55      0.57      0.56       522\n",
      "\n",
      "    accuracy                           0.94      7509\n",
      "   macro avg       0.76      0.77      0.76      7509\n",
      "weighted avg       0.94      0.94      0.94      7509\n",
      "\n",
      "9_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      7815\n",
      "         1.0       0.88      0.76      0.81       649\n",
      "\n",
      "    accuracy                           0.97      8464\n",
      "   macro avg       0.93      0.87      0.90      8464\n",
      "weighted avg       0.97      0.97      0.97      8464\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96      6912\n",
      "         1.0       0.56      0.59      0.58       588\n",
      "\n",
      "    accuracy                           0.93      7500\n",
      "   macro avg       0.76      0.78      0.77      7500\n",
      "weighted avg       0.93      0.93      0.93      7500\n",
      "\n",
      "10_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      7737\n",
      "         1.0       0.90      0.82      0.85       727\n",
      "\n",
      "    accuracy                           0.98      8464\n",
      "   macro avg       0.94      0.90      0.92      8464\n",
      "weighted avg       0.98      0.98      0.98      8464\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96      6839\n",
      "         1.0       0.63      0.65      0.64       651\n",
      "\n",
      "    accuracy                           0.94      7490\n",
      "   macro avg       0.80      0.81      0.80      7490\n",
      "weighted avg       0.94      0.94      0.94      7490\n",
      "\n",
      "11_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      7672\n",
      "         1.0       0.92      0.84      0.88       792\n",
      "\n",
      "    accuracy                           0.98      8464\n",
      "   macro avg       0.95      0.92      0.93      8464\n",
      "weighted avg       0.98      0.98      0.98      8464\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      6767\n",
      "         1.0       0.71      0.70      0.70       712\n",
      "\n",
      "    accuracy                           0.94      7479\n",
      "   macro avg       0.84      0.83      0.84      7479\n",
      "weighted avg       0.94      0.94      0.94      7479\n",
      "\n",
      "12_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      7595\n",
      "         1.0       0.90      0.83      0.86       869\n",
      "\n",
      "    accuracy                           0.97      8464\n",
      "   macro avg       0.94      0.91      0.92      8464\n",
      "weighted avg       0.97      0.97      0.97      8464\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96      6706\n",
      "         1.0       0.62      0.70      0.66       761\n",
      "\n",
      "    accuracy                           0.93      7467\n",
      "   macro avg       0.79      0.83      0.81      7467\n",
      "weighted avg       0.93      0.93      0.93      7467\n",
      "\n",
      "13_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      7554\n",
      "         1.0       0.91      0.84      0.87       910\n",
      "\n",
      "    accuracy                           0.97      8464\n",
      "   macro avg       0.95      0.91      0.93      8464\n",
      "weighted avg       0.97      0.97      0.97      8464\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95      6618\n",
      "         1.0       0.60      0.69      0.64       836\n",
      "\n",
      "    accuracy                           0.91      7454\n",
      "   macro avg       0.78      0.82      0.79      7454\n",
      "weighted avg       0.92      0.91      0.92      7454\n",
      "\n",
      "14_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      7482\n",
      "         1.0       0.92      0.84      0.88       983\n",
      "\n",
      "    accuracy                           0.97      8465\n",
      "   macro avg       0.95      0.91      0.93      8465\n",
      "weighted avg       0.97      0.97      0.97      8465\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95      6543\n",
      "         1.0       0.60      0.67      0.63       896\n",
      "\n",
      "    accuracy                           0.91      7439\n",
      "   macro avg       0.78      0.81      0.79      7439\n",
      "weighted avg       0.91      0.91      0.91      7439\n",
      "\n",
      "15_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      7433\n",
      "         1.0       0.92      0.84      0.88      1032\n",
      "\n",
      "    accuracy                           0.97      8465\n",
      "   macro avg       0.95      0.91      0.93      8465\n",
      "weighted avg       0.97      0.97      0.97      8465\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94      6472\n",
      "         1.0       0.60      0.68      0.64       952\n",
      "\n",
      "    accuracy                           0.90      7424\n",
      "   macro avg       0.78      0.81      0.79      7424\n",
      "weighted avg       0.91      0.90      0.90      7424\n",
      "\n",
      "16_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      7362\n",
      "         1.0       0.92      0.84      0.88      1103\n",
      "\n",
      "    accuracy                           0.97      8465\n",
      "   macro avg       0.95      0.91      0.93      8465\n",
      "weighted avg       0.97      0.97      0.97      8465\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94      6410\n",
      "         1.0       0.61      0.69      0.65       998\n",
      "\n",
      "    accuracy                           0.90      7408\n",
      "   macro avg       0.78      0.81      0.79      7408\n",
      "weighted avg       0.90      0.90      0.90      7408\n",
      "\n",
      "17_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      7289\n",
      "         1.0       0.90      0.84      0.87      1176\n",
      "\n",
      "    accuracy                           0.96      8465\n",
      "   macro avg       0.94      0.91      0.92      8465\n",
      "weighted avg       0.96      0.96      0.96      8465\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94      6336\n",
      "         1.0       0.64      0.66      0.65      1055\n",
      "\n",
      "    accuracy                           0.90      7391\n",
      "   macro avg       0.79      0.80      0.80      7391\n",
      "weighted avg       0.90      0.90      0.90      7391\n",
      "\n",
      "18_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      7245\n",
      "         1.0       0.92      0.85      0.88      1220\n",
      "\n",
      "    accuracy                           0.97      8465\n",
      "   macro avg       0.95      0.92      0.93      8465\n",
      "weighted avg       0.97      0.97      0.97      8465\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.92      0.93      6263\n",
      "         1.0       0.61      0.68      0.65      1110\n",
      "\n",
      "    accuracy                           0.89      7373\n",
      "   macro avg       0.78      0.80      0.79      7373\n",
      "weighted avg       0.89      0.89      0.89      7373\n",
      "\n",
      "19_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      7185\n",
      "         1.0       0.93      0.87      0.89      1280\n",
      "\n",
      "    accuracy                           0.97      8465\n",
      "   macro avg       0.95      0.93      0.94      8465\n",
      "weighted avg       0.97      0.97      0.97      8465\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.92      0.93      6220\n",
      "         1.0       0.61      0.70      0.65      1134\n",
      "\n",
      "    accuracy                           0.88      7354\n",
      "   macro avg       0.77      0.81      0.79      7354\n",
      "weighted avg       0.89      0.88      0.89      7354\n",
      "\n",
      "20_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      7112\n",
      "         1.0       0.92      0.87      0.89      1353\n",
      "\n",
      "    accuracy                           0.97      8465\n",
      "   macro avg       0.95      0.93      0.94      8465\n",
      "weighted avg       0.97      0.97      0.97      8465\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.91      0.93      6163\n",
      "         1.0       0.60      0.71      0.65      1171\n",
      "\n",
      "    accuracy                           0.88      7334\n",
      "   macro avg       0.77      0.81      0.79      7334\n",
      "weighted avg       0.89      0.88      0.88      7334\n",
      "\n",
      "21_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      7060\n",
      "         1.0       0.92      0.88      0.90      1405\n",
      "\n",
      "    accuracy                           0.97      8465\n",
      "   macro avg       0.95      0.93      0.94      8465\n",
      "weighted avg       0.97      0.97      0.97      8465\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.91      0.93      6121\n",
      "         1.0       0.61      0.71      0.65      1192\n",
      "\n",
      "    accuracy                           0.88      7313\n",
      "   macro avg       0.77      0.81      0.79      7313\n",
      "weighted avg       0.89      0.88      0.88      7313\n",
      "\n",
      "22_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98      7010\n",
      "         1.0       0.92      0.87      0.90      1455\n",
      "\n",
      "    accuracy                           0.97      8465\n",
      "   macro avg       0.95      0.93      0.94      8465\n",
      "weighted avg       0.96      0.97      0.97      8465\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.92      0.93      6047\n",
      "         1.0       0.64      0.71      0.67      1244\n",
      "\n",
      "    accuracy                           0.88      7291\n",
      "   macro avg       0.79      0.81      0.80      7291\n",
      "weighted avg       0.89      0.88      0.88      7291\n",
      "\n",
      "23_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98      6966\n",
      "         1.0       0.92      0.88      0.90      1499\n",
      "\n",
      "    accuracy                           0.97      8465\n",
      "   macro avg       0.95      0.93      0.94      8465\n",
      "weighted avg       0.97      0.97      0.97      8465\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.91      0.92      5966\n",
      "         1.0       0.63      0.72      0.67      1302\n",
      "\n",
      "    accuracy                           0.88      7268\n",
      "   macro avg       0.79      0.81      0.80      7268\n",
      "weighted avg       0.88      0.88      0.88      7268\n",
      "\n",
      "24_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98      6912\n",
      "         1.0       0.92      0.88      0.90      1552\n",
      "\n",
      "    accuracy                           0.96      8464\n",
      "   macro avg       0.95      0.93      0.94      8464\n",
      "weighted avg       0.96      0.96      0.96      8464\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.91      0.92      5902\n",
      "         1.0       0.65      0.74      0.69      1343\n",
      "\n",
      "    accuracy                           0.88      7245\n",
      "   macro avg       0.80      0.82      0.81      7245\n",
      "weighted avg       0.89      0.88      0.88      7245\n",
      "\n",
      "25_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      6847\n",
      "         1.0       0.93      0.89      0.91      1616\n",
      "\n",
      "    accuracy                           0.97      8463\n",
      "   macro avg       0.95      0.94      0.95      8463\n",
      "weighted avg       0.97      0.97      0.97      8463\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.91      0.92      5850\n",
      "         1.0       0.66      0.75      0.70      1371\n",
      "\n",
      "    accuracy                           0.88      7221\n",
      "   macro avg       0.80      0.83      0.81      7221\n",
      "weighted avg       0.89      0.88      0.88      7221\n",
      "\n",
      "26_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98      6809\n",
      "         1.0       0.93      0.88      0.91      1654\n",
      "\n",
      "    accuracy                           0.96      8463\n",
      "   macro avg       0.95      0.93      0.94      8463\n",
      "weighted avg       0.96      0.96      0.96      8463\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.92      0.93      5799\n",
      "         1.0       0.69      0.73      0.71      1396\n",
      "\n",
      "    accuracy                           0.88      7195\n",
      "   macro avg       0.81      0.82      0.82      7195\n",
      "weighted avg       0.89      0.88      0.88      7195\n",
      "\n",
      "27_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      6760\n",
      "         1.0       0.94      0.89      0.91      1703\n",
      "\n",
      "    accuracy                           0.97      8463\n",
      "   macro avg       0.96      0.94      0.95      8463\n",
      "weighted avg       0.97      0.97      0.97      8463\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.92      0.93      5743\n",
      "         1.0       0.71      0.74      0.72      1425\n",
      "\n",
      "    accuracy                           0.89      7168\n",
      "   macro avg       0.82      0.83      0.83      7168\n",
      "weighted avg       0.89      0.89      0.89      7168\n",
      "\n",
      "28_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98      6718\n",
      "         1.0       0.94      0.90      0.92      1746\n",
      "\n",
      "    accuracy                           0.97      8464\n",
      "   macro avg       0.95      0.94      0.95      8464\n",
      "weighted avg       0.97      0.97      0.97      8464\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.92      0.93      5659\n",
      "         1.0       0.71      0.73      0.72      1480\n",
      "\n",
      "    accuracy                           0.88      7139\n",
      "   macro avg       0.82      0.83      0.82      7139\n",
      "weighted avg       0.88      0.88      0.88      7139\n",
      "\n",
      "29_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      6715\n",
      "         1.0       0.94      0.90      0.92      1749\n",
      "\n",
      "    accuracy                           0.97      8464\n",
      "   macro avg       0.96      0.94      0.95      8464\n",
      "weighted avg       0.97      0.97      0.97      8464\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.93      0.93      5596\n",
      "         1.0       0.73      0.72      0.72      1514\n",
      "\n",
      "    accuracy                           0.88      7110\n",
      "   macro avg       0.83      0.82      0.82      7110\n",
      "weighted avg       0.88      0.88      0.88      7110\n",
      "\n",
      "30_period_return\n",
      "Training Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98      6655\n",
      "         1.0       0.94      0.90      0.92      1809\n",
      "\n",
      "    accuracy                           0.97      8464\n",
      "   macro avg       0.95      0.94      0.95      8464\n",
      "weighted avg       0.96      0.97      0.96      8464\n",
      "\n",
      "Testing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.93      0.93      5524\n",
      "         1.0       0.74      0.74      0.74      1556\n",
      "\n",
      "    accuracy                           0.89      7080\n",
      "   macro avg       0.84      0.83      0.84      7080\n",
      "weighted avg       0.89      0.89      0.89      7080\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>14 period RSI</th>\n",
       "      <th>14 period STOCH %K</th>\n",
       "      <th>20 period CCI</th>\n",
       "      <th>14 period ADX.</th>\n",
       "      <th>DI+</th>\n",
       "      <th>DI-</th>\n",
       "      <th>AO</th>\n",
       "      <th>MOM</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD SIGNAL</th>\n",
       "      <th>14 period stochastic RSI.</th>\n",
       "      <th>14 Williams %R</th>\n",
       "      <th>Bull.</th>\n",
       "      <th>Bear.</th>\n",
       "      <th>UO</th>\n",
       "      <th>5 period SMA</th>\n",
       "      <th>5 period EMA</th>\n",
       "      <th>10 period SMA</th>\n",
       "      <th>10 period EMA</th>\n",
       "      <th>20 period SMA</th>\n",
       "      <th>20 period EMA</th>\n",
       "      <th>30 period SMA</th>\n",
       "      <th>30 period EMA</th>\n",
       "      <th>50 period SMA</th>\n",
       "      <th>50 period EMA</th>\n",
       "      <th>100 period SMA</th>\n",
       "      <th>100 period EMA</th>\n",
       "      <th>200 period SMA</th>\n",
       "      <th>200 period EMA</th>\n",
       "      <th>20 period VAMA</th>\n",
       "      <th>9 period HMA.</th>\n",
       "      <th>TENKAN</th>\n",
       "      <th>KIJUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-30 20:00:00+00:00</th>\n",
       "      <td>9548.938477</td>\n",
       "      <td>9551.353516</td>\n",
       "      <td>9461.905273</td>\n",
       "      <td>9470.121094</td>\n",
       "      <td>9470.121094</td>\n",
       "      <td>436234240</td>\n",
       "      <td>43.381362</td>\n",
       "      <td>6.157551</td>\n",
       "      <td>-35.124219</td>\n",
       "      <td>31.479375</td>\n",
       "      <td>24.429822</td>\n",
       "      <td>35.610570</td>\n",
       "      <td>57.312221</td>\n",
       "      <td>-72.185547</td>\n",
       "      <td>23.276180</td>\n",
       "      <td>32.237108</td>\n",
       "      <td>0.672706</td>\n",
       "      <td>-93.842449</td>\n",
       "      <td>21.143400</td>\n",
       "      <td>-68.304842</td>\n",
       "      <td>34.383179</td>\n",
       "      <td>9530.991406</td>\n",
       "      <td>9522.969836</td>\n",
       "      <td>9550.146484</td>\n",
       "      <td>9532.274170</td>\n",
       "      <td>9521.879688</td>\n",
       "      <td>9519.425371</td>\n",
       "      <td>9488.424479</td>\n",
       "      <td>9499.454779</td>\n",
       "      <td>9483.326445</td>\n",
       "      <td>9449.963743</td>\n",
       "      <td>9274.551641</td>\n",
       "      <td>9343.818519</td>\n",
       "      <td>9167.232417</td>\n",
       "      <td>9277.251056</td>\n",
       "      <td>9520.481033</td>\n",
       "      <td>9516.382086</td>\n",
       "      <td>9525.540527</td>\n",
       "      <td>9481.149414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-30 21:00:00+00:00</th>\n",
       "      <td>9472.118164</td>\n",
       "      <td>9501.948242</td>\n",
       "      <td>9470.423828</td>\n",
       "      <td>9501.696289</td>\n",
       "      <td>9501.696289</td>\n",
       "      <td>198596608</td>\n",
       "      <td>49.307148</td>\n",
       "      <td>29.822366</td>\n",
       "      <td>-54.923926</td>\n",
       "      <td>30.560994</td>\n",
       "      <td>22.684835</td>\n",
       "      <td>33.066958</td>\n",
       "      <td>43.871223</td>\n",
       "      <td>-71.105469</td>\n",
       "      <td>19.197476</td>\n",
       "      <td>29.629181</td>\n",
       "      <td>0.658677</td>\n",
       "      <td>-70.177634</td>\n",
       "      <td>-24.188469</td>\n",
       "      <td>-55.712883</td>\n",
       "      <td>41.032534</td>\n",
       "      <td>9521.104102</td>\n",
       "      <td>9515.878654</td>\n",
       "      <td>9543.035938</td>\n",
       "      <td>9526.714555</td>\n",
       "      <td>9527.679492</td>\n",
       "      <td>9517.736887</td>\n",
       "      <td>9490.189128</td>\n",
       "      <td>9499.599392</td>\n",
       "      <td>9483.909727</td>\n",
       "      <td>9451.992470</td>\n",
       "      <td>9281.418203</td>\n",
       "      <td>9346.944815</td>\n",
       "      <td>9169.275508</td>\n",
       "      <td>9279.486735</td>\n",
       "      <td>9518.833410</td>\n",
       "      <td>9497.669864</td>\n",
       "      <td>9525.540527</td>\n",
       "      <td>9481.149414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-30 22:00:00+00:00</th>\n",
       "      <td>9507.450195</td>\n",
       "      <td>9668.887695</td>\n",
       "      <td>9507.450195</td>\n",
       "      <td>9668.887695</td>\n",
       "      <td>9668.887695</td>\n",
       "      <td>1712558080</td>\n",
       "      <td>68.253756</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>153.090630</td>\n",
       "      <td>30.350920</td>\n",
       "      <td>54.138884</td>\n",
       "      <td>30.705032</td>\n",
       "      <td>47.001890</td>\n",
       "      <td>100.838867</td>\n",
       "      <td>29.120341</td>\n",
       "      <td>29.527413</td>\n",
       "      <td>0.659564</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>122.357986</td>\n",
       "      <td>-39.079514</td>\n",
       "      <td>67.457069</td>\n",
       "      <td>9546.259375</td>\n",
       "      <td>9566.881668</td>\n",
       "      <td>9553.119824</td>\n",
       "      <td>9552.564217</td>\n",
       "      <td>9541.167871</td>\n",
       "      <td>9532.132202</td>\n",
       "      <td>9498.735970</td>\n",
       "      <td>9510.521218</td>\n",
       "      <td>9488.082207</td>\n",
       "      <td>9460.498165</td>\n",
       "      <td>9289.916904</td>\n",
       "      <td>9353.319929</td>\n",
       "      <td>9172.171724</td>\n",
       "      <td>9283.365480</td>\n",
       "      <td>9562.321025</td>\n",
       "      <td>9535.532704</td>\n",
       "      <td>9565.396484</td>\n",
       "      <td>9517.927246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-31 00:00:00+00:00</th>\n",
       "      <td>9700.115234</td>\n",
       "      <td>9700.115234</td>\n",
       "      <td>9667.440430</td>\n",
       "      <td>9671.981445</td>\n",
       "      <td>9671.981445</td>\n",
       "      <td>0</td>\n",
       "      <td>68.488455</td>\n",
       "      <td>88.189499</td>\n",
       "      <td>286.079214</td>\n",
       "      <td>30.528558</td>\n",
       "      <td>56.392594</td>\n",
       "      <td>28.511816</td>\n",
       "      <td>67.596054</td>\n",
       "      <td>99.013672</td>\n",
       "      <td>36.809605</td>\n",
       "      <td>30.983852</td>\n",
       "      <td>0.664047</td>\n",
       "      <td>-11.810501</td>\n",
       "      <td>135.663849</td>\n",
       "      <td>102.989044</td>\n",
       "      <td>63.807847</td>\n",
       "      <td>9572.590820</td>\n",
       "      <td>9601.914927</td>\n",
       "      <td>9563.021191</td>\n",
       "      <td>9574.276440</td>\n",
       "      <td>9555.857275</td>\n",
       "      <td>9545.451177</td>\n",
       "      <td>9506.765820</td>\n",
       "      <td>9520.938007</td>\n",
       "      <td>9492.201348</td>\n",
       "      <td>9468.791627</td>\n",
       "      <td>9299.063779</td>\n",
       "      <td>9359.630065</td>\n",
       "      <td>9175.036636</td>\n",
       "      <td>9287.236366</td>\n",
       "      <td>9562.321025</td>\n",
       "      <td>9603.718493</td>\n",
       "      <td>9581.010254</td>\n",
       "      <td>9533.541016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-31 01:00:00+00:00</th>\n",
       "      <td>9669.006836</td>\n",
       "      <td>9679.958008</td>\n",
       "      <td>9668.699219</td>\n",
       "      <td>9676.313477</td>\n",
       "      <td>9676.313477</td>\n",
       "      <td>211204096</td>\n",
       "      <td>68.835882</td>\n",
       "      <td>90.008076</td>\n",
       "      <td>237.794413</td>\n",
       "      <td>30.693507</td>\n",
       "      <td>52.364552</td>\n",
       "      <td>26.475257</td>\n",
       "      <td>86.072516</td>\n",
       "      <td>95.191406</td>\n",
       "      <td>42.760050</td>\n",
       "      <td>33.339091</td>\n",
       "      <td>0.667770</td>\n",
       "      <td>-9.991924</td>\n",
       "      <td>99.526323</td>\n",
       "      <td>88.267534</td>\n",
       "      <td>64.517337</td>\n",
       "      <td>9597.800000</td>\n",
       "      <td>9626.714443</td>\n",
       "      <td>9572.540332</td>\n",
       "      <td>9592.828629</td>\n",
       "      <td>9565.504492</td>\n",
       "      <td>9557.914254</td>\n",
       "      <td>9514.874935</td>\n",
       "      <td>9530.962231</td>\n",
       "      <td>9496.674961</td>\n",
       "      <td>9476.929739</td>\n",
       "      <td>9307.829590</td>\n",
       "      <td>9365.901030</td>\n",
       "      <td>9177.510493</td>\n",
       "      <td>9291.111804</td>\n",
       "      <td>9576.803432</td>\n",
       "      <td>9672.654315</td>\n",
       "      <td>9581.010254</td>\n",
       "      <td>9533.541016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close    Adj Close      Volume  14 period RSI  14 period STOCH %K  20 period CCI  14 period ADX.        DI+        DI-         AO         MOM       MACD  MACD SIGNAL  14 period stochastic RSI.  14 Williams %R       Bull.       Bear.         UO  5 period SMA  5 period EMA  10 period SMA  10 period EMA  20 period SMA  20 period EMA  30 period SMA  30 period EMA  50 period SMA  50 period EMA  100 period SMA  100 period EMA  200 period SMA  200 period EMA  20 period VAMA  9 period HMA.       TENKAN        KIJUN\n",
       "2020-05-30 20:00:00+00:00  9548.938477  9551.353516  9461.905273  9470.121094  9470.121094   436234240      43.381362            6.157551     -35.124219       31.479375  24.429822  35.610570  57.312221  -72.185547  23.276180    32.237108                   0.672706      -93.842449   21.143400  -68.304842  34.383179   9530.991406   9522.969836    9550.146484    9532.274170    9521.879688    9519.425371    9488.424479    9499.454779    9483.326445    9449.963743     9274.551641     9343.818519     9167.232417     9277.251056     9520.481033    9516.382086  9525.540527  9481.149414\n",
       "2020-05-30 21:00:00+00:00  9472.118164  9501.948242  9470.423828  9501.696289  9501.696289   198596608      49.307148           29.822366     -54.923926       30.560994  22.684835  33.066958  43.871223  -71.105469  19.197476    29.629181                   0.658677      -70.177634  -24.188469  -55.712883  41.032534   9521.104102   9515.878654    9543.035938    9526.714555    9527.679492    9517.736887    9490.189128    9499.599392    9483.909727    9451.992470     9281.418203     9346.944815     9169.275508     9279.486735     9518.833410    9497.669864  9525.540527  9481.149414\n",
       "2020-05-30 22:00:00+00:00  9507.450195  9668.887695  9507.450195  9668.887695  9668.887695  1712558080      68.253756          100.000000     153.090630       30.350920  54.138884  30.705032  47.001890  100.838867  29.120341    29.527413                   0.659564       -0.000000  122.357986  -39.079514  67.457069   9546.259375   9566.881668    9553.119824    9552.564217    9541.167871    9532.132202    9498.735970    9510.521218    9488.082207    9460.498165     9289.916904     9353.319929     9172.171724     9283.365480     9562.321025    9535.532704  9565.396484  9517.927246\n",
       "2020-05-31 00:00:00+00:00  9700.115234  9700.115234  9667.440430  9671.981445  9671.981445           0      68.488455           88.189499     286.079214       30.528558  56.392594  28.511816  67.596054   99.013672  36.809605    30.983852                   0.664047      -11.810501  135.663849  102.989044  63.807847   9572.590820   9601.914927    9563.021191    9574.276440    9555.857275    9545.451177    9506.765820    9520.938007    9492.201348    9468.791627     9299.063779     9359.630065     9175.036636     9287.236366     9562.321025    9603.718493  9581.010254  9533.541016\n",
       "2020-05-31 01:00:00+00:00  9669.006836  9679.958008  9668.699219  9676.313477  9676.313477   211204096      68.835882           90.008076     237.794413       30.693507  52.364552  26.475257  86.072516   95.191406  42.760050    33.339091                   0.667770       -9.991924   99.526323   88.267534  64.517337   9597.800000   9626.714443    9572.540332    9592.828629    9565.504492    9557.914254    9514.874935    9530.962231    9496.674961    9476.929739     9307.829590     9365.901030     9177.510493     9291.111804     9576.803432    9672.654315  9581.010254  9533.541016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model K-nearest neighbors.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "i = 3\n",
    "i_end = 30\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "percent_threshold = .03\n",
    "investment_amount = 10000\n",
    "training_length = 12\n",
    "while i <= i_end:\n",
    "    column_name = str(i) + \"_period_return\"\n",
    "    df[column_name] = df[\"Close\"].pct_change(periods=i)\n",
    "    # Initialize the new `Signal` column\n",
    "    signal_column_name = str(i) + \"_signal\"\n",
    "    df[signal_column_name] = 0.0\n",
    "    # Generate signal to buy stock long\n",
    "    df.loc[(df[column_name] >= (percent_threshold)), signal_column_name] = 1\n",
    "    # Drop all NaN values from the DataFrame\n",
    "    df = df.dropna()\n",
    "    y = df[signal_column_name]\n",
    "    # set up X for ml \n",
    "    X = df[[\"14 period RSI\", \"14 period STOCH %K\", \"20 period CCI\", \"14 period ADX.\", \"DI+\", \"DI-\", \"AO\", \"MOM\", \"MACD\", \"MACD SIGNAL\", \"14 period stochastic RSI.\", \"14 Williams %R\", \"Bull.\", \"Bear.\", \"UO\", \"5 period SMA\", \"5 period EMA\", \"10 period SMA\", \"10 period EMA\", \"20 period SMA\", \"20 period EMA\", \"30 period SMA\", \"30 period EMA\", \"50 period SMA\", \"50 period EMA\", \"100 period SMA\", \"100 period EMA\", \"200 period SMA\", \"200 period EMA\", \"20 period VAMA\", \"9 period HMA.\", \"TENKAN\", \"KIJUN\"]].shift().dropna().copy()\n",
    "    y_count = y.value_counts()\n",
    "    training_begin = X.index.min()\n",
    "    # Use the following code to select the ending period for the training data: `training_end = X.index.min() + DateOffset(months=3)`\n",
    "    training_end = X.index.min() + DateOffset(months=training_length)\n",
    "    # Generate the X_train and y_train DataFrames using loc to select the rows from `training_begin` up to `training_end`\n",
    "    # Hint: Use `loc[training_begin:training_end]` for X_train and y_train\n",
    "    X_train = X.loc[training_begin:training_end]\n",
    "    y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "    # Generate the X_test and y_test DataFrames using loc to select from `training_end` to the last row in the DataFrame.\n",
    "    # Hint: Use `loc[training_end:]` for X_test and y_test\n",
    "    X_test = X.loc[training_end:]\n",
    "    y_test = y.loc[training_end:]\n",
    "\n",
    "    # Use StandardScaler to scale the X_train and X_test data.\n",
    "    scaler = StandardScaler()\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    " \n",
    "    # Fit the model to the data using X_train_scaled and y_train\n",
    "    model = model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Use the trained model to predict the trading signals for the training data.\n",
    "    training_signal_predictions = model.predict(X_train_scaled)\n",
    "\n",
    "    # Evaluate the model using a classification report\n",
    "    training_report_train = classification_report(y_train, training_signal_predictions)\n",
    "    print(column_name)\n",
    "    print(\"Training Report\")\n",
    "    print(training_report_train)\n",
    "\n",
    "    # Use the trained model to predict the trading signals for the testing data.\n",
    "    testing_signal_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model's ability to predict the trading signal for the testing data using a classification report\n",
    "    training_report_test = classification_report(y_test, testing_signal_predictions)\n",
    "    print(\"Testing Report\")\n",
    "    print(training_report_test)\n",
    "\n",
    "    df = df.drop([column_name, signal_column_name], axis=1)\n",
    "    i+=1\n",
    "\n",
    "display(df.head())\n",
    "#display(list(df.columns))\n",
    "#display(y_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investment_amount = 10000 * .05\n",
    "\n",
    "# # Initialize the new `Signal` column\n",
    "# df['signal'] = 0.0\n",
    "# # Generate signal to buy stock long\n",
    "# df.loc[(df['three_period_return'] >= ((investment_amount * 0.00001))), 'signal'] = 1\n",
    "# # Generate signal to sell stock short\n",
    "# #df.loc[(df['three_period_return'] < (investment_amount * 0.00001)), 'signal'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Copy the new \"signal\" column to a new Series called `y`.\n",
    "# y = df['signal']\n",
    "# # set up X for ml \n",
    "# X = df[[\"14 period RSI\", \"14 period STOCH %K\", \"20 period CCI\", \"14 period ADX.\", \"DI+\", \"DI-\", \"AO\", \"MOM\", \"MACD\", \"MACD SIGNAL\", \"14 period stochastic RSI.\", \"14 Williams %R\", \"Bull.\", \"Bear.\", \"UO\", \"5 period SMA\", \"5 period EMA\", \"10 period SMA\", \"10 period EMA\", \"20 period SMA\", \"20 period EMA\", \"30 period SMA\", \"30 period EMA\", \"50 period SMA\", \"50 period EMA\", \"100 period SMA\", \"100 period EMA\", \"200 period SMA\", \"200 period EMA\", \"20 period VAMA\", \"9 period HMA.\", \"TENKAN\", \"KIJUN\"]].shift().dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    15316\n",
       "1.0      661\n",
       "Name: 5_signal, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value counts for -1 and 1\n",
    "# y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-10 19:00:00+00:00\n",
      "2020-08-10 19:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# # Use the following code to select the start of the training period: `training_begin = X.index.min()`\n",
    "# training_begin = X.index.min()\n",
    "# print(training_begin)\n",
    "\n",
    "# # Use the following code to select the ending period for the training data: `training_end = X.index.min() + DateOffset(months=3)`\n",
    "# training_end = X.index.min() + DateOffset(months=3)\n",
    "# print(training_end)\n",
    "\n",
    "# # Generate the X_train and y_train DataFrames using loc to select the rows from `training_begin` up to `training_end`\n",
    "# # Hint: Use `loc[training_begin:training_end]` for X_train and y_train\n",
    "# X_train = X.loc[training_begin:training_end]\n",
    "# y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# # Generate the X_test and y_test DataFrames using loc to select from `training_end` to the last row in the DataFrame.\n",
    "# # Hint: Use `loc[training_end:]` for X_test and y_test\n",
    "# X_test = X.loc[training_end:]\n",
    "# y_test = y.loc[training_end:]\n",
    "\n",
    "# # Use StandardScaler to scale the X_train and X_test data.\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_scaler = scaler.fit(X_train)\n",
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "# X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      2072\n",
      "         1.0       1.00      0.35      0.51        26\n",
      "\n",
      "    accuracy                           0.99      2098\n",
      "   macro avg       1.00      0.67      0.76      2098\n",
      "weighted avg       0.99      0.99      0.99      2098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = SVC()\n",
    " \n",
    "# # Fit the model to the data using X_train_scaled and y_train\n",
    "# model = model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Use the trained model to predict the trading signals for the training data.\n",
    "# training_signal_predictions = model.predict(X_train_scaled)\n",
    "\n",
    "# # Evaluate the model using a classification report\n",
    "# from sklearn.metrics import classification_report\n",
    "# training_report = classification_report(y_train, training_signal_predictions)\n",
    "# print(training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98     13244\n",
      "         1.0       0.00      0.00      0.00       635\n",
      "\n",
      "    accuracy                           0.95     13879\n",
      "   macro avg       0.48      0.50      0.49     13879\n",
      "weighted avg       0.91      0.95      0.93     13879\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/charlesbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/charlesbrown/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to predict the trading signals for the testing data.\n",
    "testing_signal_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's ability to predict the trading signal for the testing data using a classification report\n",
    "training_report = classification_report(y_test, testing_signal_predictions)\n",
    "print(training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'three_period_return'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'three_period_return'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4x/jx46p2kn29bbg4k41vh6c4gh0000gn/T/ipykernel_5894/3789461993.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'signal'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting_signal_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'signal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"three_period_return\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"three_period_return\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'three_period_return'"
     ]
    }
   ],
   "source": [
    " # Create a new empty predictions DataFrame using code provided below.\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "predictions_df['signal'] = testing_signal_predictions\n",
    "predictions_df['signal'].value_counts()\n",
    "predictions_df[\"three_period_return\"] = df[\"three_period_return\"]\n",
    "\n",
    "\n",
    "intial_investment = 10000\n",
    "# Add in actual returns and calculate trading returns\n",
    "predictions_df['actual_return'] = df['actual_return']\n",
    "predictions_df['trading_algorithm_returns_3'] = predictions_df.loc[predictions_df[\"signal\"]==1][\"three_period_return\"]\n",
    "#predictions_df[\"trading_algorithm_returns_5\"] = \n",
    "predictions_df[\"trading_algorithm_returns_3\"].fillna(0, inplace=True)\n",
    "predictions_df[\"trading_algo_returns_3_+1\"] = ((predictions_df[\"trading_algorithm_returns_3\"] + 1) * intial_investment)\n",
    "# we need to add trading algo cumulative returns in order to plot agaisnt actual returns and see how well our algo performed compared to actual returns\n",
    "\n",
    "predictions_df[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "\n",
    "(1 + predictions_df[['actual_return', 'trading_algo_returns_3_+1']]).cumprod().plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5c03b34df633f5a55f03c9fd4bf57224531b1cf45a05bf3195213c2a88d9ef9"
  },
  "kernelspec": {
   "display_name": "Python (apidev)",
   "language": "python",
   "name": "apidev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
